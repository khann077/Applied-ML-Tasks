{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "f2d5be44-3708-4405-b93d-9de77bd5fbda",
      "metadata": {
        "id": "f2d5be44-3708-4405-b93d-9de77bd5fbda"
      },
      "source": [
        "---\n",
        "<h1 style=\"text-align: center;\">\n",
        "CSCI 4521: Applied Machine Learning (Fall 2024)\n",
        "</h1>\n",
        "\n",
        "<h1 style=\"text-align: center;\">\n",
        "Homework 3\n",
        "</h1>\n",
        "\n",
        "<h3 style=\"text-align: center;\">\n",
        "(Due Tue, Oct. 29, 11:59 PM CT)\n",
        "</h3>\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8d5be1aa-5953-4fae-b666-a06957d504d6",
      "metadata": {
        "id": "8d5be1aa-5953-4fae-b666-a06957d504d6"
      },
      "source": [
        "### The RMS Titanic was a British ocean liner considered by many as \"unsinkable.\" Unfortunately, the Titanic hit an iceberge and sank on April 15, 1912 on her trip from Southampton, England to New York City, USA. There were not enough lifeboards onboard for everyone and, as a result, an estimated 1500 people died out of the 2224 passengers and crew onboard. The Titanic disaster was one of the deadliest ship sinkings. There was a large element of luck involved in surviving the shipwreck but some people were more likely to survive than others."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c4f1f05b-2d70-4b6b-ac92-72647781315b",
      "metadata": {
        "id": "c4f1f05b-2d70-4b6b-ac92-72647781315b"
      },
      "source": [
        "![rms-titanic-14047.png](attachment:d3b8257e-f179-4545-8953-e44343a5f64d.png)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bf573c05-3b91-4fe5-a0f4-9038560c93d5",
      "metadata": {
        "id": "bf573c05-3b91-4fe5-a0f4-9038560c93d5"
      },
      "source": [
        "### In this homework, your task is to predict whether a passenger will survive the shipwreck or not. You need to use machine learning and develop classification models to accomplish this task. The only data you have available is passenger data in the dataset `titanic_dataset_csci4521.csv` which consists of the following features:\n",
        "- ### Passenger ID,\n",
        "- ### Ticket class (1 = first class, 2 = second class, 3 = third class),\n",
        "- ### Passenger name,\n",
        "- ### Sex,\n",
        "- ### Age,\n",
        "- ### Number of siblings or spouses aboard,\n",
        "- ### Number of parents or children aboard,\n",
        "- ### Ticket number,\n",
        "- ### Fare,\n",
        "- ### Cabin number, and\n",
        "- ### Port of Embarkation (C = Cherbourg, Q = Queenstown, S = Southampton)\n",
        "### and label:\n",
        "- ### Survived ($y_i=1$) or\n",
        "- ### Not survived ($y_i = 0$).\n",
        "### You must decide if and how to clean and preprocess the data, which classification algorithms to use, which and how to tune any hyperparameters, how to measure performance, which models to select, and which final model to use."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4753a60e-803f-40a9-b64d-6e34d98ee1bf",
      "metadata": {
        "id": "4753a60e-803f-40a9-b64d-6e34d98ee1bf"
      },
      "source": [
        "### You can use any of the coding packages we've used in class (numpy, pandas, pyspark, scikit-learn, etc.) and you must write and submit working code. Reminder, you cannot use ChatGPT or similar technologies. Please see the syllabus for more details."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "251f9f7c-f61d-41d9-a0bc-03803ee34377",
      "metadata": {
        "id": "251f9f7c-f61d-41d9-a0bc-03803ee34377"
      },
      "source": [
        "### You also need to submit a short report of your work describing all steps you took, explanations of why you took those steps, results, what you learned, how you might use what you learned in the future, and your conclusions. We expect the report to be well-written and clearly describe everything you've done and why."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7d379108-9103-43da-ac09-2074efe2737c",
      "metadata": {
        "id": "7d379108-9103-43da-ac09-2074efe2737c"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dd51e918-fc0c-40df-9e41-ea75d18637ea",
      "metadata": {
        "id": "dd51e918-fc0c-40df-9e41-ea75d18637ea"
      },
      "source": [
        "### Write your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1 - The Basics: Setting up imports and starting a pyspark session."
      ],
      "metadata": {
        "id": "1qV_Izf1e3em"
      },
      "id": "1qV_Izf1e3em"
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "b965d31b-a2d6-46a6-a7bd-80d6ad9f86a0",
      "metadata": {
        "id": "b965d31b-a2d6-46a6-a7bd-80d6ad9f86a0"
      },
      "outputs": [],
      "source": [
        "# Install PySpark on Colab\n",
        "# !pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "67c08bed-660a-4033-8917-d40927dc5f8a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "67c08bed-660a-4033-8917-d40927dc5f8a",
        "outputId": "28a88469-8710-4b5e-92aa-fad307579b56"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# PySpark imports\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col, isnan, when, count, median, expr, round\n",
        "from pyspark.sql import functions as F\n",
        "\n",
        "from pyspark.ml.feature import Imputer, StandardScaler, VectorAssembler, StringIndexer, OneHotEncoder\n",
        "from pyspark.ml.functions import vector_to_array\n",
        "from pyspark.ml.linalg import Vectors\n",
        "from pyspark.ml.classification import RandomForestClassifier, LogisticRegression, DecisionTreeClassifier\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
        "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
        "\n",
        "# Colab imports\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# sklearn imports\n",
        "from sklearn.model_selection import train_test_split, LeaveOneOut\n",
        "\n",
        "# Misc Import\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "b46ea36a-bd14-4914-ae11-5e1ced4b3bd0",
      "metadata": {
        "id": "b46ea36a-bd14-4914-ae11-5e1ced4b3bd0"
      },
      "outputs": [],
      "source": [
        "# Build PySpark session\n",
        "spark = SparkSession.builder.appName(\"HW3\").getOrCreate()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2 - Loading the Dataset"
      ],
      "metadata": {
        "id": "0hmQtfOIhQfs"
      },
      "id": "0hmQtfOIhQfs"
    },
    {
      "cell_type": "code",
      "source": [
        "# Read CSV Data\n",
        "df = spark.read.csv(\"/content/drive/MyDrive/colab_data/titanic_dataset_csci4521.csv\", header=True, inferSchema=True)\n",
        "\n",
        "# No. of Samples\n",
        "print(\"Number of samples = \", df.count())\n",
        "# No. of Features available\n",
        "print(\"Number of features = \", len(df.columns))\n",
        "\n",
        "# Print head upto 10\n",
        "display(df.show(10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "id": "adIc763FhXSu",
        "outputId": "efd95a5e-4c85-4a1a-81eb-d0b4670067fe"
      },
      "id": "adIc763FhXSu",
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of samples =  894\n",
            "Number of features =  12\n",
            "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
            "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|\n",
            "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
            "|          1|       0|     3|Braund, Mr. Owen ...|  male|22.0|    1|    0|       A/5 21171|   7.25| NULL|       S|\n",
            "|          2|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|        PC 17599|71.2833|  C85|       C|\n",
            "|          3|       1|     3|Heikkinen, Miss. ...|female|26.0|    0|    0|STON/O2. 3101282|  7.925| NULL|       S|\n",
            "|          4|       1|     1|Futrelle, Mrs. Ja...|female|35.0|    1|    0|          113803|   53.1| C123|       S|\n",
            "|          5|       0|     3|Allen, Mr. Willia...|  male|35.0|    0|    0|          373450|   8.05| NULL|       S|\n",
            "|          6|       0|     3|    Moran, Mr. James|  male|NULL|    0|    0|          330877| 8.4583| NULL|       Q|\n",
            "|          7|       0|     1|McCarthy, Mr. Tim...|  male|54.0|    0|    0|           17463|51.8625|  E46|       S|\n",
            "|          8|       0|     3|Palsson, Master. ...|  male| 2.0|    3|    1|          349909| 21.075| NULL|       S|\n",
            "|          9|       1|     3|Johnson, Mrs. Osc...|female|27.0|    0|    2|          347742|11.1333| NULL|       S|\n",
            "|         10|       1|     2|Nasser, Mrs. Nich...|female|14.0|    1|    0|          237736|30.0708| NULL|       C|\n",
            "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "None"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Step 3 - Examining Nulls"
      ],
      "metadata": {
        "id": "CFvbSbNuocX8"
      },
      "id": "CFvbSbNuocX8"
    },
    {
      "cell_type": "code",
      "source": [
        "# Examining Nulls\n",
        "null_counts = df.select([\n",
        "    count(when(col(column).isNull(), column)).alias(column)\n",
        "    for column in df.columns\n",
        "])\n",
        "\n",
        "# Display the count of null values for each column\n",
        "null_counts.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GDpuVRpXsooj",
        "outputId": "59017f18-2471-43e9-aa72-adff34eddf33"
      },
      "id": "GDpuVRpXsooj",
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+--------+------+----+---+---+-----+-----+------+----+-----+--------+\n",
            "|PassengerId|Survived|Pclass|Name|Sex|Age|SibSp|Parch|Ticket|Fare|Cabin|Embarked|\n",
            "+-----------+--------+------+----+---+---+-----+-----+------+----+-----+--------+\n",
            "|          0|       0|    11|   4|  5|178|    1|    0|     0|   0|  690|      17|\n",
            "+-----------+--------+------+----+---+---+-----+-----+------+----+-----+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Step 4 - Cleaning and Splitting Data"
      ],
      "metadata": {
        "id": "PY8u6VkFN_Rb"
      },
      "id": "PY8u6VkFN_Rb"
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop cabin - the data here is mostly null\n",
        "df = df.drop(\"Cabin\")\n",
        "\n",
        "# Impute Null's in age using random sampling within Pclass\n",
        "ages_per_class = df.groupBy(\"Pclass\").agg(F.collect_list(\"Age\").alias(\"class_age\"))\n",
        "\n",
        "df = df.join(ages_per_class, on=\"Pclass\", how=\"left\")\n",
        "\n",
        "random_sample_code_string = \"class_age[floor(rand()*size(class_age))]\"\n",
        "\n",
        "df = df.withColumn(\n",
        "    \"Age\",\n",
        "    F.when(\n",
        "        df[\"Age\"].isNull(), F.expr(random_sample_code_string)\n",
        "    ).otherwise(df[\"Age\"])\n",
        ")\n",
        "\n",
        "# Drop the added helper col\n",
        "df = df.drop(\"class_age\")\n",
        "\n",
        "# Sanity Check\n",
        "print(\"Samples Before: \", df.count())\n",
        "# Drop all samples with any columns as null\n",
        "df = df.dropna(how=\"any\")\n",
        "print(\"Samples After: \", df.count())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9hbMHj5tOCL7",
        "outputId": "90437dc2-ccb0-4e90-f6b4-26e2cda665c1"
      },
      "id": "9hbMHj5tOCL7",
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Samples Before:  894\n",
            "Samples After:  859\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Separate Labels\n",
        "label = df.select(\"Survived\")\n",
        "\n",
        "# Drop irrelevant/uneccessary features (reasonings in report)\n",
        "features_to_remove = [\"PassengerId\", \"Name\", \"Ticket\"]\n",
        "df = df.drop(*features_to_remove)\n",
        "\n",
        "# Show new df\n",
        "df.show(20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L9KB-UC4SsGw",
        "outputId": "6e7e5263-49a2-4df4-c20b-2e1cb9ac5e6a"
      },
      "id": "L9KB-UC4SsGw",
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+--------+------+----+-----+-----+-------+--------+\n",
            "|Pclass|Survived|   Sex| Age|SibSp|Parch|   Fare|Embarked|\n",
            "+------+--------+------+----+-----+-----+-------+--------+\n",
            "|     3|       0|  male|22.0|    1|    0|   7.25|       S|\n",
            "|     1|       1|female|38.0|    1|    0|71.2833|       C|\n",
            "|     3|       1|female|26.0|    0|    0|  7.925|       S|\n",
            "|     1|       1|female|35.0|    1|    0|   53.1|       S|\n",
            "|     3|       0|  male|35.0|    0|    0|   8.05|       S|\n",
            "|     3|       0|  male|11.0|    0|    0| 8.4583|       Q|\n",
            "|     1|       0|  male|54.0|    0|    0|51.8625|       S|\n",
            "|     3|       0|  male| 2.0|    3|    1| 21.075|       S|\n",
            "|     3|       1|female|27.0|    0|    2|11.1333|       S|\n",
            "|     2|       1|female|14.0|    1|    0|30.0708|       C|\n",
            "|     3|       1|female| 4.0|    1|    1|   16.7|       S|\n",
            "|     1|       1|female|58.0|    0|    0|  26.55|       S|\n",
            "|     3|       0|  male|39.0|    1|    5| 31.275|       S|\n",
            "|     3|       0|female|14.0|    0|    0| 7.8542|       S|\n",
            "|     2|       1|female|55.0|    0|    0|   16.0|       S|\n",
            "|     3|       0|  male| 2.0|    4|    1| 29.125|       Q|\n",
            "|     2|       1|  male|36.0|    0|    0|   13.0|       S|\n",
            "|     3|       0|female|31.0|    1|    0|   18.0|       S|\n",
            "|     3|       1|female|30.5|    0|    0|  7.225|       C|\n",
            "|     2|       0|  male|35.0|    0|    0|   26.0|       S|\n",
            "+------+--------+------+----+-----+-----+-------+--------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 5 - Using different classification methods"
      ],
      "metadata": {
        "id": "_VkcSBPdU_nz"
      },
      "id": "_VkcSBPdU_nz"
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting up future operations by encoding, scaling and vectorizing\n",
        "indexer_sex = StringIndexer(inputCol=\"Sex\", outputCol=\"SexIndex\")\n",
        "indexer_embarked = StringIndexer(inputCol=\"Embarked\", outputCol=\"EmbarkedIndex\")\n",
        "encoder = OneHotEncoder(inputCols=[\"SexIndex\", \"EmbarkedIndex\"],\n",
        "                        outputCols=[\"SexVec\", \"EmbarkedVec\"])\n",
        "\n",
        "# Assemble into vector columns\n",
        "assembler = VectorAssembler(\n",
        "    inputCols=[\"Pclass\", \"Age\", \"SibSp\", \"Parch\", \"Fare\", \"SexVec\", \"EmbarkedVec\"],\n",
        "    outputCol=\"vector_features\"\n",
        ")\n",
        "\n",
        "# Scaling\n",
        "scaler = StandardScaler(inputCol=\"vector_features\", outputCol=\"features\")\n",
        "\n",
        "# Transform df\n",
        "df = indexer_sex.fit(df).transform(df)\n",
        "df = indexer_embarked.fit(df).transform(df)\n",
        "df = encoder.fit(df).transform(df)\n",
        "df = assembler.transform(df)\n",
        "df = scaler.fit(df).transform(df)\n",
        "\n",
        "# Final DataFrame with features and label columns only\n",
        "final_df = df.select(\"features\", \"Survived\")\n",
        "final_df = final_df.withColumnRenamed(\"Survived\", \"label\")\n",
        "\n",
        "final_df.show(20)\n"
      ],
      "metadata": {
        "id": "PPnxsH8FgJ-K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b74bb1b-93ce-4e46-a882-6f0cbf8cf670"
      },
      "id": "PPnxsH8FgJ-K",
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+-----+\n",
            "|            features|label|\n",
            "+--------------------+-----+\n",
            "|[3.58375316685557...|    0|\n",
            "|[1.19458438895185...|    1|\n",
            "|(8,[0,1,4,6],[3.5...|    1|\n",
            "|[1.19458438895185...|    1|\n",
            "|[3.58375316685557...|    0|\n",
            "|(8,[0,1,4,5],[3.5...|    0|\n",
            "|[1.19458438895185...|    0|\n",
            "|[3.58375316685557...|    0|\n",
            "|[3.58375316685557...|    1|\n",
            "|[2.38916877790371...|    1|\n",
            "|[3.58375316685557...|    1|\n",
            "|(8,[0,1,4,6],[1.1...|    1|\n",
            "|[3.58375316685557...|    0|\n",
            "|(8,[0,1,4,6],[3.5...|    0|\n",
            "|(8,[0,1,4,6],[2.3...|    1|\n",
            "|[3.58375316685557...|    0|\n",
            "|[2.38916877790371...|    1|\n",
            "|[3.58375316685557...|    0|\n",
            "|(8,[0,1,4,7],[3.5...|    1|\n",
            "|[2.38916877790371...|    0|\n",
            "+--------------------+-----+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Split data into train test and validation"
      ],
      "metadata": {
        "id": "smamCLkbD5kN"
      },
      "id": "smamCLkbD5kN"
    },
    {
      "cell_type": "code",
      "source": [
        "train, valid, test = final_df.randomSplit([0.8, 0.1, 0.1], seed = 5782267)"
      ],
      "metadata": {
        "id": "-jUN4t6REAA5"
      },
      "id": "-jUN4t6REAA5",
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.1 Logistic Regression"
      ],
      "metadata": {
        "id": "oVcaPMIJVOmV"
      },
      "id": "oVcaPMIJVOmV"
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the Logistic regression model with hyperparameters\n",
        "lr_model = LogisticRegression()\n",
        "param_grid = ParamGridBuilder().addGrid(lr_model.regParam, [0.01, 0.1, 1.0]).build()\n",
        "\n",
        "# Test\n",
        "cv = CrossValidator(estimator=lr_model, estimatorParamMaps=param_grid,\n",
        "                    evaluator=BinaryClassificationEvaluator(labelCol = \"label\"), numFolds=5)\n",
        "cv_model = cv.fit(train)\n",
        "\n",
        "best_lr_model = cv_model.bestModel\n",
        "\n",
        "print(\"Best Logistic Regression Model Params: \", best_lr_model.extractParamMap())"
      ],
      "metadata": {
        "id": "AvCCGUofVVfr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d61712bf-7a64-4a41-e5c4-8d043511c5de"
      },
      "id": "AvCCGUofVVfr",
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Logistic Regression Model Params:  {Param(parent='LogisticRegression_2bd4be8be406', name='aggregationDepth', doc='suggested depth for treeAggregate (>= 2).'): 2, Param(parent='LogisticRegression_2bd4be8be406', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.0, Param(parent='LogisticRegression_2bd4be8be406', name='family', doc='The name of family which is a description of the label distribution to be used in the model. Supported options: auto, binomial, multinomial'): 'auto', Param(parent='LogisticRegression_2bd4be8be406', name='featuresCol', doc='features column name.'): 'features', Param(parent='LogisticRegression_2bd4be8be406', name='fitIntercept', doc='whether to fit an intercept term.'): True, Param(parent='LogisticRegression_2bd4be8be406', name='labelCol', doc='label column name.'): 'label', Param(parent='LogisticRegression_2bd4be8be406', name='maxBlockSizeInMB', doc='maximum memory in MB for stacking input data into blocks. Data is stacked within partitions. If more than remaining data size in a partition then it is adjusted to the data size. Default 0.0 represents choosing optimal value, depends on specific algorithm. Must be >= 0.'): 0.0, Param(parent='LogisticRegression_2bd4be8be406', name='maxIter', doc='max number of iterations (>= 0).'): 100, Param(parent='LogisticRegression_2bd4be8be406', name='predictionCol', doc='prediction column name.'): 'prediction', Param(parent='LogisticRegression_2bd4be8be406', name='probabilityCol', doc='Column name for predicted class conditional probabilities. Note: Not all models output well-calibrated probability estimates! These probabilities should be treated as confidences, not precise probabilities.'): 'probability', Param(parent='LogisticRegression_2bd4be8be406', name='rawPredictionCol', doc='raw prediction (a.k.a. confidence) column name.'): 'rawPrediction', Param(parent='LogisticRegression_2bd4be8be406', name='regParam', doc='regularization parameter (>= 0).'): 0.01, Param(parent='LogisticRegression_2bd4be8be406', name='standardization', doc='whether to standardize the training features before fitting the model.'): True, Param(parent='LogisticRegression_2bd4be8be406', name='threshold', doc='Threshold in binary classification prediction, in range [0, 1]. If threshold and thresholds are both set, they must match.e.g. if threshold is p, then thresholds must be equal to [1-p, p].'): 0.5, Param(parent='LogisticRegression_2bd4be8be406', name='tol', doc='the convergence tolerance for iterative algorithms (>= 0).'): 1e-06}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.2 Decision Trees"
      ],
      "metadata": {
        "id": "3EFuOASvVRta"
      },
      "id": "3EFuOASvVRta"
    },
    {
      "cell_type": "code",
      "source": [
        "# Build DT model with hyperparams\n",
        "dt = DecisionTreeClassifier(featuresCol=\"features\", labelCol=\"label\")\n",
        "param_grid_dt = ParamGridBuilder().addGrid(dt.maxDepth, [5, 10, 15]).addGrid(dt.maxBins, [20, 40, 60]).build()\n",
        "\n",
        "# Test\n",
        "cv_dt = CrossValidator(estimator=dt, estimatorParamMaps=param_grid_dt,\n",
        "                       evaluator=BinaryClassificationEvaluator(labelCol=\"label\"), numFolds=5)\n",
        "cvModel_dt = cv_dt.fit(train)\n",
        "\n",
        "best_dt_model = cvModel_dt.bestModel\n",
        "\n",
        "print(\"Best Decision Tree Model Params: \",  best_dt_model.extractParamMap())"
      ],
      "metadata": {
        "id": "gXJYtEt3VKhh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f22c66d-a665-494c-c21d-4869645355ef"
      },
      "id": "gXJYtEt3VKhh",
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Decision Tree Model Params:  {Param(parent='DecisionTreeClassifier_6edf7939ee9c', name='cacheNodeIds', doc='If false, the algorithm will pass trees to executors to match instances with nodes. If true, the algorithm will cache node IDs for each instance. Caching can speed up training of deeper trees. Users can set how often should the cache be checkpointed or disable it by setting checkpointInterval.'): False, Param(parent='DecisionTreeClassifier_6edf7939ee9c', name='checkpointInterval', doc='set checkpoint interval (>= 1) or disable checkpoint (-1). E.g. 10 means that the cache will get checkpointed every 10 iterations. Note: this setting will be ignored if the checkpoint directory is not set in the SparkContext.'): 10, Param(parent='DecisionTreeClassifier_6edf7939ee9c', name='featuresCol', doc='features column name.'): 'features', Param(parent='DecisionTreeClassifier_6edf7939ee9c', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini', Param(parent='DecisionTreeClassifier_6edf7939ee9c', name='labelCol', doc='label column name.'): 'label', Param(parent='DecisionTreeClassifier_6edf7939ee9c', name='leafCol', doc='Leaf indices column name. Predicted leaf index of each instance in each tree by preorder.'): '', Param(parent='DecisionTreeClassifier_6edf7939ee9c', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 40, Param(parent='DecisionTreeClassifier_6edf7939ee9c', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 15, Param(parent='DecisionTreeClassifier_6edf7939ee9c', name='maxMemoryInMB', doc='Maximum memory in MB allocated to histogram aggregation. If too small, then 1 node will be split per iteration, and its aggregates may exceed this size.'): 256, Param(parent='DecisionTreeClassifier_6edf7939ee9c', name='minInfoGain', doc='Minimum information gain for a split to be considered at a tree node.'): 0.0, Param(parent='DecisionTreeClassifier_6edf7939ee9c', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 1, Param(parent='DecisionTreeClassifier_6edf7939ee9c', name='minWeightFractionPerNode', doc='Minimum fraction of the weighted sample count that each child must have after split. If a split causes the fraction of the total weight in the left or right child to be less than minWeightFractionPerNode, the split will be discarded as invalid. Should be in interval [0.0, 0.5).'): 0.0, Param(parent='DecisionTreeClassifier_6edf7939ee9c', name='predictionCol', doc='prediction column name.'): 'prediction', Param(parent='DecisionTreeClassifier_6edf7939ee9c', name='probabilityCol', doc='Column name for predicted class conditional probabilities. Note: Not all models output well-calibrated probability estimates! These probabilities should be treated as confidences, not precise probabilities.'): 'probability', Param(parent='DecisionTreeClassifier_6edf7939ee9c', name='rawPredictionCol', doc='raw prediction (a.k.a. confidence) column name.'): 'rawPrediction', Param(parent='DecisionTreeClassifier_6edf7939ee9c', name='seed', doc='random seed.'): -6742106464098577159}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.3 Random Forest"
      ],
      "metadata": {
        "id": "S8aj6Cw9VWa0"
      },
      "id": "S8aj6Cw9VWa0"
    },
    {
      "cell_type": "code",
      "source": [
        "# Build Random Forest Model with Hyperparams\n",
        "rf = RandomForestClassifier(featuresCol=\"features\", labelCol=\"label\")\n",
        "paramGrid_rf = ParamGridBuilder().addGrid(rf.numTrees, [40, 100, 160]).addGrid(rf.maxDepth, [4, 10, 16]).build()\n",
        "\n",
        "# Test\n",
        "cv_rf = CrossValidator(estimator=rf, estimatorParamMaps=paramGrid_rf,\n",
        "                       evaluator=BinaryClassificationEvaluator(labelCol=\"label\"), numFolds=5)\n",
        "\n",
        "cvModel_rf = cv_rf.fit(train)\n",
        "\n",
        "best_rf_model = cvModel_rf.bestModel\n",
        "\n",
        "print(\"Best Random Forest Model Params: \", best_rf_model.extractParamMap())"
      ],
      "metadata": {
        "id": "JNr9l9hSVHIj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d52e5f29-901f-4aca-ae0d-9f4bc737910b"
      },
      "id": "JNr9l9hSVHIj",
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Random Forest Model Params:  {Param(parent='RandomForestClassifier_c40f4f99965f', name='bootstrap', doc='Whether bootstrap samples are used when building trees.'): True, Param(parent='RandomForestClassifier_c40f4f99965f', name='cacheNodeIds', doc='If false, the algorithm will pass trees to executors to match instances with nodes. If true, the algorithm will cache node IDs for each instance. Caching can speed up training of deeper trees. Users can set how often should the cache be checkpointed or disable it by setting checkpointInterval.'): False, Param(parent='RandomForestClassifier_c40f4f99965f', name='checkpointInterval', doc='set checkpoint interval (>= 1) or disable checkpoint (-1). E.g. 10 means that the cache will get checkpointed every 10 iterations. Note: this setting will be ignored if the checkpoint directory is not set in the SparkContext.'): 10, Param(parent='RandomForestClassifier_c40f4f99965f', name='featureSubsetStrategy', doc=\"The number of features to consider for splits at each tree node. Supported options: 'auto' (choose automatically for task: If numTrees == 1, set to 'all'. If numTrees > 1 (forest), set to 'sqrt' for classification and to 'onethird' for regression), 'all' (use all features), 'onethird' (use 1/3 of the features), 'sqrt' (use sqrt(number of features)), 'log2' (use log2(number of features)), 'n' (when n is in the range (0, 1.0], use n * number of features. When n is in the range (1, number of features), use n features). default = 'auto'\"): 'auto', Param(parent='RandomForestClassifier_c40f4f99965f', name='featuresCol', doc='features column name.'): 'features', Param(parent='RandomForestClassifier_c40f4f99965f', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini', Param(parent='RandomForestClassifier_c40f4f99965f', name='labelCol', doc='label column name.'): 'label', Param(parent='RandomForestClassifier_c40f4f99965f', name='leafCol', doc='Leaf indices column name. Predicted leaf index of each instance in each tree by preorder.'): '', Param(parent='RandomForestClassifier_c40f4f99965f', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 32, Param(parent='RandomForestClassifier_c40f4f99965f', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 4, Param(parent='RandomForestClassifier_c40f4f99965f', name='maxMemoryInMB', doc='Maximum memory in MB allocated to histogram aggregation. If too small, then 1 node will be split per iteration, and its aggregates may exceed this size.'): 256, Param(parent='RandomForestClassifier_c40f4f99965f', name='minInfoGain', doc='Minimum information gain for a split to be considered at a tree node.'): 0.0, Param(parent='RandomForestClassifier_c40f4f99965f', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 1, Param(parent='RandomForestClassifier_c40f4f99965f', name='minWeightFractionPerNode', doc='Minimum fraction of the weighted sample count that each child must have after split. If a split causes the fraction of the total weight in the left or right child to be less than minWeightFractionPerNode, the split will be discarded as invalid. Should be in interval [0.0, 0.5).'): 0.0, Param(parent='RandomForestClassifier_c40f4f99965f', name='numTrees', doc='Number of trees to train (>= 1).'): 160, Param(parent='RandomForestClassifier_c40f4f99965f', name='predictionCol', doc='prediction column name.'): 'prediction', Param(parent='RandomForestClassifier_c40f4f99965f', name='probabilityCol', doc='Column name for predicted class conditional probabilities. Note: Not all models output well-calibrated probability estimates! These probabilities should be treated as confidences, not precise probabilities.'): 'probability', Param(parent='RandomForestClassifier_c40f4f99965f', name='rawPredictionCol', doc='raw prediction (a.k.a. confidence) column name.'): 'rawPrediction', Param(parent='RandomForestClassifier_c40f4f99965f', name='seed', doc='random seed.'): 470395999770335240, Param(parent='RandomForestClassifier_c40f4f99965f', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 1.0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 6: Comparing Models"
      ],
      "metadata": {
        "id": "fUxvAzCGr9-a"
      },
      "id": "fUxvAzCGr9-a"
    },
    {
      "cell_type": "code",
      "source": [
        "# Helper Function\n",
        "def model_performance(model, data, labelCol=\"label\"):\n",
        "    # Metrics were chosen based on this article : https://medium.com/analytics-vidhya/evaluation-metrics-for-classification-models-e2f0d8009d69\n",
        "    predictions = model.transform(valid)\n",
        "\n",
        "    evaluate_acc = MulticlassClassificationEvaluator(labelCol=labelCol, metricName=\"accuracy\")\n",
        "    evaluate_f1 = MulticlassClassificationEvaluator(labelCol=labelCol, metricName=\"f1\")\n",
        "    evaluate_precision = MulticlassClassificationEvaluator(labelCol=labelCol, metricName=\"weightedPrecision\")\n",
        "    evaluate_recall = MulticlassClassificationEvaluator(labelCol=labelCol, metricName=\"weightedRecall\")\n",
        "\n",
        "    accuracy = evaluate_acc.evaluate(predictions)\n",
        "    f1 = evaluate_f1.evaluate(predictions)\n",
        "    precision = evaluate_precision.evaluate(predictions)\n",
        "    recall = evaluate_recall.evaluate(predictions)\n",
        "\n",
        "    results = {\n",
        "        \"Accuracy\": accuracy,\n",
        "        \"F1\": f1,\n",
        "        \"Precision\": precision,\n",
        "        \"Recall\": recall\n",
        "    }\n",
        "\n",
        "    return results\n",
        "\n",
        "# Evaluate each model\n",
        "results_lr = model_performance(best_lr_model, final_df)\n",
        "results_dt = model_performance(best_dt_model, final_df)\n",
        "results_rf = model_performance(best_rf_model, final_df)"
      ],
      "metadata": {
        "id": "VVE18MAXsAwo"
      },
      "id": "VVE18MAXsAwo",
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 7: Summarize and Conclude"
      ],
      "metadata": {
        "id": "oHchDv-uAS5u"
      },
      "id": "oHchDv-uAS5u"
    },
    {
      "cell_type": "code",
      "source": [
        "# create a table to better see results\n",
        "results_df = pd.DataFrame([results_lr, results_dt, results_rf])\n",
        "results_df.index = [\"Logistic Regression\", \"Decision Tree\", \"Random Forest\"]\n",
        "results_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "fFiqEqsYAVzc",
        "outputId": "e6e20a32-37f4-4dc7-86d7-b1de93cac66f"
      },
      "id": "fFiqEqsYAVzc",
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                     Accuracy        F1  Precision    Recall\n",
              "Logistic Regression  0.764706  0.756624   0.771992  0.764706\n",
              "Decision Tree        0.741176  0.734767   0.742415  0.741176\n",
              "Random Forest        0.788235  0.775913   0.815092  0.788235"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-496dc114-1cda-4725-8355-bf3813efe4c6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Logistic Regression</th>\n",
              "      <td>0.764706</td>\n",
              "      <td>0.756624</td>\n",
              "      <td>0.771992</td>\n",
              "      <td>0.764706</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Decision Tree</th>\n",
              "      <td>0.741176</td>\n",
              "      <td>0.734767</td>\n",
              "      <td>0.742415</td>\n",
              "      <td>0.741176</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Random Forest</th>\n",
              "      <td>0.788235</td>\n",
              "      <td>0.775913</td>\n",
              "      <td>0.815092</td>\n",
              "      <td>0.788235</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-496dc114-1cda-4725-8355-bf3813efe4c6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-496dc114-1cda-4725-8355-bf3813efe4c6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-496dc114-1cda-4725-8355-bf3813efe4c6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-8e7c4e4c-7a2e-41c7-a96c-1975b1dae2cb\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8e7c4e4c-7a2e-41c7-a96c-1975b1dae2cb')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-8e7c4e4c-7a2e-41c7-a96c-1975b1dae2cb button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_6b6129ae-1563-48d0-89f1-fb6b40ba65ca\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('results_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_6b6129ae-1563-48d0-89f1-fb6b40ba65ca button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('results_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "results_df",
              "summary": "{\n  \"name\": \"results_df\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"Accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.023529411764705854,\n        \"min\": 0.7411764705882353,\n        \"max\": 0.788235294117647,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.7647058823529411,\n          0.7411764705882353,\n          0.788235294117647\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.020586277334513865,\n        \"min\": 0.7347669256381797,\n        \"max\": 0.7759127789046654,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.7566237964719937,\n          0.7347669256381797,\n          0.7759127789046654\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.03654771758406892,\n        \"min\": 0.7424148606811145,\n        \"max\": 0.8150920974450386,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.7719917171562236,\n          0.7424148606811145,\n          0.8150920974450386\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.02352941176470591,\n        \"min\": 0.7411764705882353,\n        \"max\": 0.7882352941176471,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.7647058823529412,\n          0.7411764705882353,\n          0.7882352941176471\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 8: Apply best performing model to test data"
      ],
      "metadata": {
        "id": "HBkhoBDUE5JF"
      },
      "id": "HBkhoBDUE5JF"
    },
    {
      "cell_type": "code",
      "source": [
        "combined_data = train.union(valid)\n",
        "best_model = dt.fit(combined_data)\n",
        "\n",
        "# Prediction on test data\n",
        "test_predictions = best_model.transform(test)\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\")\n",
        "\n",
        "# Calculate evaluation metrics on the test set\n",
        "accuracy = evaluator.evaluate(test_predictions, {evaluator.metricName: \"accuracy\"})\n",
        "f1_score = evaluator.evaluate(test_predictions, {evaluator.metricName: \"f1\"})\n",
        "weighted_precision = evaluator.evaluate(test_predictions, {evaluator.metricName: \"weightedPrecision\"})\n",
        "weighted_recall = evaluator.evaluate(test_predictions, {evaluator.metricName: \"weightedRecall\"})\n",
        "\n",
        "print(f\"Test Accuracy: {accuracy}\")\n",
        "print(f\"Test F1 Score: {f1_score}\")\n",
        "print(f\"Test Weighted Precision: {weighted_precision}\")\n",
        "print(f\"Test Weighted Recall: {weighted_recall}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gt1LjY0IE4vh",
        "outputId": "40258ae4-c9c9-4ad0-b096-734b0a802158"
      },
      "id": "gt1LjY0IE4vh",
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.8222222222222222\n",
            "Test F1 Score: 0.8199539252170831\n",
            "Test Weighted Precision: 0.8211530283700867\n",
            "Test Weighted Recall: 0.8222222222222222\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bdc3199a-80a9-4a63-a2d7-56ed2d16755c",
      "metadata": {
        "id": "bdc3199a-80a9-4a63-a2d7-56ed2d16755c"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "df1eaa39-d9bd-410c-beb5-9ca37bdf3d32",
      "metadata": {
        "id": "df1eaa39-d9bd-410c-beb5-9ca37bdf3d32"
      },
      "source": [
        "### Write your report here"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Report"
      ],
      "metadata": {
        "id": "8SDwxuSOCDcL"
      },
      "id": "8SDwxuSOCDcL"
    },
    {
      "cell_type": "markdown",
      "id": "142f066b-5655-4e1e-9bb1-ae4cc5f54565",
      "metadata": {
        "id": "142f066b-5655-4e1e-9bb1-ae4cc5f54565"
      },
      "source": [
        "1.   Step 1 - The Basics\n",
        "\n",
        "*   Reasons:\n",
        "*   I chose to use PySpark because it provides mutliple useful packages and functions for various steps across the task.\n",
        "*   Robust and good for the moderate sized dataset that we have\n",
        "*   Allows good interoperability with other packages if needed later."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Step 2 - Examining data\n",
        "\n",
        "*  Reasons:\n",
        "*  Loaded the data just to see what the features types were, what data was largely missing etc."
      ],
      "metadata": {
        "id": "nQ-a89xykSht"
      },
      "id": "nQ-a89xykSht"
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Step 3 - Examining Nulls\n",
        "\n",
        "*  I print the empty values in the dataset and observe that age has multiple missing values.\n",
        "*  Here is my strategy to deal with missing values. Since age is a numerical value I will replace it with the median of the dataset. For the remaining features, since they are categorical and low in numbers removing them shouldn't affect the learning too much so I will drop those rows"
      ],
      "metadata": {
        "id": "euxcq0zhgOD0"
      },
      "id": "euxcq0zhgOD0"
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Step 4 - Cleaning the data\n",
        "\n",
        "\n",
        "\n",
        "*   Noticed that the cabin column had too many nulls. Decided to drop the feature as filling its values from such a small subset of data would likely yield baised results, and the feature data is not likely ot have much impact on our overall predicitions because we can ascertain similar information using Pclass\n",
        "*   Decided to impute the values for age using random sampling within a PClass, to provide some semblance of realism ot the data, without introducing too much bias.\n",
        "*   Removed the feature PassengerID because it is linearly increasing and not an intrinsic property of the passeneger so it could produce negative effects on the predicitions\n",
        "*   Removed Name, Ticket for similar reasons to PassenegerID\n",
        "*   Removed the label from the df and stored it seperately, we'll use it later\n",
        "\n"
      ],
      "metadata": {
        "id": "iLreEJnlP3q5"
      },
      "id": "iLreEJnlP3q5"
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Step 5: Using the data\n",
        "*   First I transformed the data into a useful format. This meant scaling features to avoid variance and encoding categorical features like sex, embarked etc\n",
        "* Then I vectorised the data to be able to provide it into the PySpark functions since they require vectors as input.\n",
        "* Finally I split the data into a train test and validation split. This allows us to train and tests the data but also use some of it to tune models and parameters.\n",
        "\n",
        "* I decided to use models for logistic regression, decision trees and random forests. Since the task was classification these seemed like the most useful models. Additionally that task is only binary classiication.\n",
        "* Logistic regression might have been a good choice because the features were scaled and linearly independant for a lower dimension size and the task at hand is binary classification.\n",
        "* Decision Tree and Random Forest are also reaosnable models as they can find deeper connections among features over longer computations.\n",
        "\n",
        "* HyperParams: I chose values for hyperparams mostly at random and by looking at some commonly used values as well as the slides."
      ],
      "metadata": {
        "id": "Ugegd4u2dmhn"
      },
      "id": "Ugegd4u2dmhn"
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Step 6: Comparing the data\n",
        "\n",
        "* I wrote a simple helper function to get characteristics of the models. The features chosen were from the articlee linked in the code block."
      ],
      "metadata": {
        "id": "njhmI6gYfqUW"
      },
      "id": "njhmI6gYfqUW"
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. Step 7 and 8: Comparing the data\n",
        "\n",
        "* Finally I compared the models performance on the test data and noticed that Decision Trees had the best performance on the test data."
      ],
      "metadata": {
        "id": "_AoxO5_af78p"
      },
      "id": "_AoxO5_af78p"
    },
    {
      "cell_type": "markdown",
      "source": [
        "What I Learned\n",
        "\n",
        "* Data cleaning and imputing to produce viable data\n",
        "* Using pyspark for classification tasks\n",
        "* How to evaluate and tune models."
      ],
      "metadata": {
        "id": "BxSkushjgB0H"
      },
      "id": "BxSkushjgB0H"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Future Use\n",
        "\n",
        "* Classification is a very useful technique.\n",
        "* I could extend this given a data set with more features to be more accurate.\n",
        "* Use these skills for open source projects on Kaggle\n",
        "* Tackle small classification problems on open data sets in medical and financial settings(own interest)"
      ],
      "metadata": {
        "id": "8erym7_LgD8s"
      },
      "id": "8erym7_LgD8s"
    },
    {
      "cell_type": "markdown",
      "id": "4dfd1c26-217d-400f-abf6-4b3a92e9a175",
      "metadata": {
        "id": "4dfd1c26-217d-400f-abf6-4b3a92e9a175"
      },
      "source": [
        "Results\n",
        "\n",
        "* I used python code to clean data, create useful froms of it, and then use a machine learning model to fit the data, thereby finding that the Decision Tree mdoel fits the data best, and can predict survival of a passenger with roughly 82% accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e353c9e6-e532-42c3-9288-3c50ed48a32f",
      "metadata": {
        "id": "e353c9e6-e532-42c3-9288-3c50ed48a32f"
      },
      "source": [
        "---"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}