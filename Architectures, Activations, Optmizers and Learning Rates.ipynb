{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "e8c94c2f-ab44-4318-941a-2d474e1e8441",
      "metadata": {
        "id": "e8c94c2f-ab44-4318-941a-2d474e1e8441"
      },
      "source": [
        "---\n",
        "<h1 style=\"text-align: center;\">\n",
        "CSCI 4521: Applied Machine Learning (Fall 2024)\n",
        "</h1>\n",
        "\n",
        "<h1 style=\"text-align: center;\">\n",
        "Homework 5\n",
        "</h1>\n",
        "\n",
        "<h3 style=\"text-align: center;\">\n",
        "(Due Tue, Nov. 26, 11:59 PM CT)\n",
        "</h3>\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4bafea59-8cdb-4666-8016-d3d2341fd062",
      "metadata": {
        "id": "4bafea59-8cdb-4666-8016-d3d2341fd062"
      },
      "source": [
        "![nn.png](attachment:fde9d58f-62e0-4c07-aacb-8334e3ef1027.png)\n",
        "\n",
        "Image from https://aibusiness.com/ml/how-neural-networks-can-think-like-humans-and-why-it-matters#close-modal"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bf573c05-3b91-4fe5-a0f4-9038560c93d5",
      "metadata": {
        "id": "bf573c05-3b91-4fe5-a0f4-9038560c93d5"
      },
      "source": [
        "### In this homework, your task is to experiment with fully-connected, feed-forward neural networks to predict whether a sonar signal bounces off a metal cylinder or a cylindrical rock. The only data you have available is the sonar data in the dataset `sonar_csci4521_hw5.csv`. Each row is a sample and columns are the sonar features, and the last column is the label of metal (\"M\") or rock (\"R\").\n",
        "\n",
        "### You do not need to clean or preprocess the data in this homework except encoding the label using the `LabelEncoder`; focus on building and training neural networks. You still need to determine what kind of neural network to use, which and how to tune any hyperparameters, how to measure performance, which models to select, and which final model to use. We do expect that you will try a few different architectures (e.g., number of layers, number of units in each layer), activation functions, and gradient descent algorithms (e.g., stochastic gradient descent, Adagrad, RMSprop, Adam). We also expect that you will tune hyperparameters (not necessarily with cross validation but definitely only using the training dataset) and measure the performance of the final model on a held-out test set. Additionally, we expect you to track the performance of your experiments using Tensorboard, for example, track the average loss and accuracy per epoch on the training and test sets."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4753a60e-803f-40a9-b64d-6e34d98ee1bf",
      "metadata": {
        "id": "4753a60e-803f-40a9-b64d-6e34d98ee1bf"
      },
      "source": [
        "### You must use **PyTorch** to build and train your neural network, no other packages will be accepted (for example, you cannot use Tensorflow). If you use anything other than PyTorch to build your network, you will receive no credit for this homework. Make sure to write and submit clean, working code. Reminder, you cannot use ChatGPT or similar technologies. Please see the syllabus for more details."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "251f9f7c-f61d-41d9-a0bc-03803ee34377",
      "metadata": {
        "id": "251f9f7c-f61d-41d9-a0bc-03803ee34377"
      },
      "source": [
        "### You also need to submit a short report of your work describing all steps you took, explanations of why you took those steps, results, what you learned, how you might use what you learned in the future, and your conclusions. We expect the report to be well-written and clearly describe everything you've done and why."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7d379108-9103-43da-ac09-2074efe2737c",
      "metadata": {
        "id": "7d379108-9103-43da-ac09-2074efe2737c"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dd51e918-fc0c-40df-9e41-ea75d18637ea",
      "metadata": {
        "id": "dd51e918-fc0c-40df-9e41-ea75d18637ea"
      },
      "source": [
        "### Write your code here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "id": "57d1f6e4-02c7-4ee5-8595-5ea438c46fc2",
      "metadata": {
        "id": "57d1f6e4-02c7-4ee5-8595-5ea438c46fc2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa0f9ac9-da7c-424f-9d00-8885a1e15542"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# PyTorch Imports\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "# Sklearn Imports\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "\n",
        "# Google Colab Imports\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Misc Imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "id": "c7c61462-2afd-4e05-8f3a-786ff1aca712",
      "metadata": {
        "id": "c7c61462-2afd-4e05-8f3a-786ff1aca712",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 638
        },
        "outputId": "cf73e997-bfde-477c-8568-66bfc1e6c671"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of samples =  0     208\n",
            "1     208\n",
            "2     208\n",
            "3     208\n",
            "4     208\n",
            "     ... \n",
            "56    208\n",
            "57    208\n",
            "58    208\n",
            "59    208\n",
            "60    208\n",
            "Length: 61, dtype: int64\n",
            "Number of features =  61\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       0       1       2       3       4       5       6       7       8   \\\n",
              "0  0.0200  0.0371  0.0428  0.0207  0.0954  0.0986  0.1539  0.1601  0.3109   \n",
              "1  0.0453  0.0523  0.0843  0.0689  0.1183  0.2583  0.2156  0.3481  0.3337   \n",
              "2  0.0262  0.0582  0.1099  0.1083  0.0974  0.2280  0.2431  0.3771  0.5598   \n",
              "3  0.0100  0.0171  0.0623  0.0205  0.0205  0.0368  0.1098  0.1276  0.0598   \n",
              "4  0.0762  0.0666  0.0481  0.0394  0.0590  0.0649  0.1209  0.2467  0.3564   \n",
              "5  0.0286  0.0453  0.0277  0.0174  0.0384  0.0990  0.1201  0.1833  0.2105   \n",
              "6  0.0317  0.0956  0.1321  0.1408  0.1674  0.1710  0.0731  0.1401  0.2083   \n",
              "7  0.0519  0.0548  0.0842  0.0319  0.1158  0.0922  0.1027  0.0613  0.1465   \n",
              "8  0.0223  0.0375  0.0484  0.0475  0.0647  0.0591  0.0753  0.0098  0.0684   \n",
              "9  0.0164  0.0173  0.0347  0.0070  0.0187  0.0671  0.1056  0.0697  0.0962   \n",
              "\n",
              "       9   ...      51      52      53      54      55      56      57  \\\n",
              "0  0.2111  ...  0.0027  0.0065  0.0159  0.0072  0.0167  0.0180  0.0084   \n",
              "1  0.2872  ...  0.0084  0.0089  0.0048  0.0094  0.0191  0.0140  0.0049   \n",
              "2  0.6194  ...  0.0232  0.0166  0.0095  0.0180  0.0244  0.0316  0.0164   \n",
              "3  0.1264  ...  0.0121  0.0036  0.0150  0.0085  0.0073  0.0050  0.0044   \n",
              "4  0.4459  ...  0.0031  0.0054  0.0105  0.0110  0.0015  0.0072  0.0048   \n",
              "5  0.3039  ...  0.0045  0.0014  0.0038  0.0013  0.0089  0.0057  0.0027   \n",
              "6  0.3513  ...  0.0201  0.0248  0.0131  0.0070  0.0138  0.0092  0.0143   \n",
              "7  0.2838  ...  0.0081  0.0120  0.0045  0.0121  0.0097  0.0085  0.0047   \n",
              "8  0.1487  ...  0.0145  0.0128  0.0145  0.0058  0.0049  0.0065  0.0093   \n",
              "9  0.0251  ...  0.0090  0.0223  0.0179  0.0084  0.0068  0.0032  0.0035   \n",
              "\n",
              "       58      59  60  \n",
              "0  0.0090  0.0032   R  \n",
              "1  0.0052  0.0044   R  \n",
              "2  0.0095  0.0078   R  \n",
              "3  0.0040  0.0117   R  \n",
              "4  0.0107  0.0094   R  \n",
              "5  0.0051  0.0062   R  \n",
              "6  0.0036  0.0103   R  \n",
              "7  0.0048  0.0053   R  \n",
              "8  0.0059  0.0022   R  \n",
              "9  0.0056  0.0040   R  \n",
              "\n",
              "[10 rows x 61 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-db41d495-6994-458f-96d2-5f111aad9af9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>51</th>\n",
              "      <th>52</th>\n",
              "      <th>53</th>\n",
              "      <th>54</th>\n",
              "      <th>55</th>\n",
              "      <th>56</th>\n",
              "      <th>57</th>\n",
              "      <th>58</th>\n",
              "      <th>59</th>\n",
              "      <th>60</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0200</td>\n",
              "      <td>0.0371</td>\n",
              "      <td>0.0428</td>\n",
              "      <td>0.0207</td>\n",
              "      <td>0.0954</td>\n",
              "      <td>0.0986</td>\n",
              "      <td>0.1539</td>\n",
              "      <td>0.1601</td>\n",
              "      <td>0.3109</td>\n",
              "      <td>0.2111</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0027</td>\n",
              "      <td>0.0065</td>\n",
              "      <td>0.0159</td>\n",
              "      <td>0.0072</td>\n",
              "      <td>0.0167</td>\n",
              "      <td>0.0180</td>\n",
              "      <td>0.0084</td>\n",
              "      <td>0.0090</td>\n",
              "      <td>0.0032</td>\n",
              "      <td>R</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0453</td>\n",
              "      <td>0.0523</td>\n",
              "      <td>0.0843</td>\n",
              "      <td>0.0689</td>\n",
              "      <td>0.1183</td>\n",
              "      <td>0.2583</td>\n",
              "      <td>0.2156</td>\n",
              "      <td>0.3481</td>\n",
              "      <td>0.3337</td>\n",
              "      <td>0.2872</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0084</td>\n",
              "      <td>0.0089</td>\n",
              "      <td>0.0048</td>\n",
              "      <td>0.0094</td>\n",
              "      <td>0.0191</td>\n",
              "      <td>0.0140</td>\n",
              "      <td>0.0049</td>\n",
              "      <td>0.0052</td>\n",
              "      <td>0.0044</td>\n",
              "      <td>R</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0262</td>\n",
              "      <td>0.0582</td>\n",
              "      <td>0.1099</td>\n",
              "      <td>0.1083</td>\n",
              "      <td>0.0974</td>\n",
              "      <td>0.2280</td>\n",
              "      <td>0.2431</td>\n",
              "      <td>0.3771</td>\n",
              "      <td>0.5598</td>\n",
              "      <td>0.6194</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0232</td>\n",
              "      <td>0.0166</td>\n",
              "      <td>0.0095</td>\n",
              "      <td>0.0180</td>\n",
              "      <td>0.0244</td>\n",
              "      <td>0.0316</td>\n",
              "      <td>0.0164</td>\n",
              "      <td>0.0095</td>\n",
              "      <td>0.0078</td>\n",
              "      <td>R</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0100</td>\n",
              "      <td>0.0171</td>\n",
              "      <td>0.0623</td>\n",
              "      <td>0.0205</td>\n",
              "      <td>0.0205</td>\n",
              "      <td>0.0368</td>\n",
              "      <td>0.1098</td>\n",
              "      <td>0.1276</td>\n",
              "      <td>0.0598</td>\n",
              "      <td>0.1264</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0121</td>\n",
              "      <td>0.0036</td>\n",
              "      <td>0.0150</td>\n",
              "      <td>0.0085</td>\n",
              "      <td>0.0073</td>\n",
              "      <td>0.0050</td>\n",
              "      <td>0.0044</td>\n",
              "      <td>0.0040</td>\n",
              "      <td>0.0117</td>\n",
              "      <td>R</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0762</td>\n",
              "      <td>0.0666</td>\n",
              "      <td>0.0481</td>\n",
              "      <td>0.0394</td>\n",
              "      <td>0.0590</td>\n",
              "      <td>0.0649</td>\n",
              "      <td>0.1209</td>\n",
              "      <td>0.2467</td>\n",
              "      <td>0.3564</td>\n",
              "      <td>0.4459</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0031</td>\n",
              "      <td>0.0054</td>\n",
              "      <td>0.0105</td>\n",
              "      <td>0.0110</td>\n",
              "      <td>0.0015</td>\n",
              "      <td>0.0072</td>\n",
              "      <td>0.0048</td>\n",
              "      <td>0.0107</td>\n",
              "      <td>0.0094</td>\n",
              "      <td>R</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.0286</td>\n",
              "      <td>0.0453</td>\n",
              "      <td>0.0277</td>\n",
              "      <td>0.0174</td>\n",
              "      <td>0.0384</td>\n",
              "      <td>0.0990</td>\n",
              "      <td>0.1201</td>\n",
              "      <td>0.1833</td>\n",
              "      <td>0.2105</td>\n",
              "      <td>0.3039</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0045</td>\n",
              "      <td>0.0014</td>\n",
              "      <td>0.0038</td>\n",
              "      <td>0.0013</td>\n",
              "      <td>0.0089</td>\n",
              "      <td>0.0057</td>\n",
              "      <td>0.0027</td>\n",
              "      <td>0.0051</td>\n",
              "      <td>0.0062</td>\n",
              "      <td>R</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.0317</td>\n",
              "      <td>0.0956</td>\n",
              "      <td>0.1321</td>\n",
              "      <td>0.1408</td>\n",
              "      <td>0.1674</td>\n",
              "      <td>0.1710</td>\n",
              "      <td>0.0731</td>\n",
              "      <td>0.1401</td>\n",
              "      <td>0.2083</td>\n",
              "      <td>0.3513</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0201</td>\n",
              "      <td>0.0248</td>\n",
              "      <td>0.0131</td>\n",
              "      <td>0.0070</td>\n",
              "      <td>0.0138</td>\n",
              "      <td>0.0092</td>\n",
              "      <td>0.0143</td>\n",
              "      <td>0.0036</td>\n",
              "      <td>0.0103</td>\n",
              "      <td>R</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.0519</td>\n",
              "      <td>0.0548</td>\n",
              "      <td>0.0842</td>\n",
              "      <td>0.0319</td>\n",
              "      <td>0.1158</td>\n",
              "      <td>0.0922</td>\n",
              "      <td>0.1027</td>\n",
              "      <td>0.0613</td>\n",
              "      <td>0.1465</td>\n",
              "      <td>0.2838</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0081</td>\n",
              "      <td>0.0120</td>\n",
              "      <td>0.0045</td>\n",
              "      <td>0.0121</td>\n",
              "      <td>0.0097</td>\n",
              "      <td>0.0085</td>\n",
              "      <td>0.0047</td>\n",
              "      <td>0.0048</td>\n",
              "      <td>0.0053</td>\n",
              "      <td>R</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.0223</td>\n",
              "      <td>0.0375</td>\n",
              "      <td>0.0484</td>\n",
              "      <td>0.0475</td>\n",
              "      <td>0.0647</td>\n",
              "      <td>0.0591</td>\n",
              "      <td>0.0753</td>\n",
              "      <td>0.0098</td>\n",
              "      <td>0.0684</td>\n",
              "      <td>0.1487</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0145</td>\n",
              "      <td>0.0128</td>\n",
              "      <td>0.0145</td>\n",
              "      <td>0.0058</td>\n",
              "      <td>0.0049</td>\n",
              "      <td>0.0065</td>\n",
              "      <td>0.0093</td>\n",
              "      <td>0.0059</td>\n",
              "      <td>0.0022</td>\n",
              "      <td>R</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.0164</td>\n",
              "      <td>0.0173</td>\n",
              "      <td>0.0347</td>\n",
              "      <td>0.0070</td>\n",
              "      <td>0.0187</td>\n",
              "      <td>0.0671</td>\n",
              "      <td>0.1056</td>\n",
              "      <td>0.0697</td>\n",
              "      <td>0.0962</td>\n",
              "      <td>0.0251</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0090</td>\n",
              "      <td>0.0223</td>\n",
              "      <td>0.0179</td>\n",
              "      <td>0.0084</td>\n",
              "      <td>0.0068</td>\n",
              "      <td>0.0032</td>\n",
              "      <td>0.0035</td>\n",
              "      <td>0.0056</td>\n",
              "      <td>0.0040</td>\n",
              "      <td>R</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10 rows × 61 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-db41d495-6994-458f-96d2-5f111aad9af9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-db41d495-6994-458f-96d2-5f111aad9af9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-db41d495-6994-458f-96d2-5f111aad9af9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-f6f73b99-c6b3-46c1-a997-abfa6aef70cb\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f6f73b99-c6b3-46c1-a997-abfa6aef70cb')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-f6f73b99-c6b3-46c1-a997-abfa6aef70cb button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 59
        }
      ],
      "source": [
        "# Step 1: Load Data\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/colab_data/sonar_csci4521_hw5.csv\", header=None)\n",
        "\n",
        "# No. of Samples\n",
        "print(\"Number of samples = \", df.count())\n",
        "# No. of Features available\n",
        "print(\"Number of features = \", len(df.columns))\n",
        "\n",
        "# Print head upto 10\n",
        "df.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Make train and test data\n",
        "\n",
        "# Seperate features and labels\n",
        "X = df.iloc[:, :-1].values\n",
        "y = LabelEncoder().fit_transform(df.iloc[:, -1].values)\n",
        "\n",
        "# Split into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=5782267, stratify=y)\n",
        "\n",
        "# Standardize\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Training tensors\n",
        "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
        "\n",
        "# Testing tensors\n",
        "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
        "\n",
        "# Create PyTorch datasets and dataloaders\n",
        "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "id": "9H6PjT8CcquO"
      },
      "id": "9H6PjT8CcquO",
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Helper function to build models\n",
        "\n",
        "def build_model(input_size, hidden_sizes, output_size, activation_fn):\n",
        "    '''\n",
        "    Function to help build models of different architectures. Lets me setup\n",
        "    models of different layer numbers, input sizes, output sizes, and hidden\n",
        "    sizes, as well as multiple activation functions.\n",
        "    '''\n",
        "    layers = []\n",
        "    prev_size = input_size\n",
        "    for next_size in hidden_sizes:\n",
        "        # Add a layer and the function after\n",
        "        layers.append(nn.Linear(prev_size, next_size))\n",
        "        layers.append(activation_fn())\n",
        "\n",
        "        # Track what previous layer size was to connect the next NN layer\n",
        "        prev_size = next_size\n",
        "\n",
        "    # Add the output layer\n",
        "    layers.append(nn.Linear(prev_size, output_size))\n",
        "    return nn.Sequential(*layers)"
      ],
      "metadata": {
        "id": "O_ykL8tDgiXM"
      },
      "id": "O_ykL8tDgiXM",
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Helper function for epoch training for model\n",
        "\n",
        "def train_model(model, train_loader, optimizer_name, learning_rate, epochs=50):\n",
        "    '''\n",
        "    Helper function to train models. Uses different optimizers and learning rates, as\n",
        "    well as modifiable epochs.\n",
        "    '''\n",
        "    # Variable to track loss\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    if optimizer_name == \"Adam\":\n",
        "        optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "    elif optimizer_name == \"SGD\":\n",
        "        optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
        "    elif optimizer_name == \"RMSprop\":\n",
        "        optimizer = optim.RMSprop(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    # Add TensorBoard\n",
        "    writer = SummaryWriter(log_dir=f'runs/sonar_{optimizer_name}_lr{learning_rate}')\n",
        "\n",
        "    # Training loop\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        epoch_loss = 0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        # Batch train the model per epoch\n",
        "        for X_batch, y_batch in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(X_batch)\n",
        "            loss = criterion(outputs, y_batch)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            correct += (predicted == y_batch).sum().item()\n",
        "            total += y_batch.size(0)\n",
        "\n",
        "        train_accuracy = 100 * correct / total\n",
        "        writer.add_scalar('Loss/Train', epoch_loss / len(train_loader), epoch)\n",
        "        writer.add_scalar('Accuracy/Train', train_accuracy, epoch)\n",
        "\n",
        "    writer.close()\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "Ar-QhtuZgmpx"
      },
      "id": "Ar-QhtuZgmpx",
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: Helper function to evaluate each created model on test data\n",
        "\n",
        "def evaluate_model(model, test_loader):\n",
        "    '''\n",
        "    Evaluates model accuracy for the test data.\n",
        "    '''\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for X_batch, y_batch in test_loader:\n",
        "            outputs = model(X_batch)\n",
        "            _, predicted = outputs.max(1)\n",
        "            correct += (predicted == y_batch).sum().item()\n",
        "            total += y_batch.size(0)\n",
        "\n",
        "    test_accuracy = 100 * correct / total\n",
        "    print(f'Test Accuracy: {test_accuracy:.2f}%')\n",
        "    return test_accuracy"
      ],
      "metadata": {
        "id": "_B8LKr7pgwWC"
      },
      "id": "_B8LKr7pgwWC",
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 6: \"Main\" function, code that runs the tests for different architectures\n",
        "# activators, learning rates and optimizers,\n",
        "\n",
        "# Possible Architectures\n",
        "architectures = [[64, 32], [128, 64, 32], [256, 128, 64, 32]]\n",
        "\n",
        "# Possible activation functions\n",
        "activations = [nn.ReLU, nn.Tanh, nn.Sigmoid]\n",
        "\n",
        "# Possible optimizers\n",
        "optimizers = [\"Adam\", \"SGD\", \"RMSprop\"]\n",
        "\n",
        "# Possible learning rates\n",
        "learning_rates = [0.001, 0.01]\n",
        "\n",
        "# Reasoning in report\n",
        "epochs = 40\n",
        "# input_size = X_train.shape[1]\n",
        "# output_size = 2\n",
        "\n",
        "# Reporting variables\n",
        "best_model = None\n",
        "best_accuracy = 0\n",
        "params = []\n",
        "\n",
        "# Testing loop\n",
        "for arch in architectures:\n",
        "    for activation_fn in activations:\n",
        "        for optimizer in optimizers:\n",
        "            for lr in learning_rates:\n",
        "                print(f\"Training with Architecture={arch}, Activation={activation_fn.__name__}, Optimizer={optimizer}, LR={lr}\")\n",
        "                model = build_model(input_size, arch, output_size, activation_fn)\n",
        "                model = train_model(model, train_loader, optimizer, lr, epochs)\n",
        "                accuracy = evaluate_model(model, test_loader)\n",
        "                if accuracy > best_accuracy:\n",
        "                    best_accuracy = accuracy\n",
        "                    best_model = model\n",
        "                    params = [arch, activation_fn, optimizer, epochs]\n",
        "\n",
        "print(f\"Best Model Accuracy: {best_accuracy:.2f}%\")\n",
        "print(f\"Best Model Parameters: {params}\")\n",
        "torch.save(best_model.state_dict(), 'best_sonar_model.pth')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FYJuCdN8g1Hs",
        "outputId": "50b7eebf-a433-4809-b5b1-0b3e71bbd1eb"
      },
      "id": "FYJuCdN8g1Hs",
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training with Architecture=[64, 32], Activation=ReLU, Optimizer=Adam, LR=0.001\n",
            "Test Accuracy: 78.57%\n",
            "Training with Architecture=[64, 32], Activation=ReLU, Optimizer=Adam, LR=0.01\n",
            "Test Accuracy: 83.33%\n",
            "Training with Architecture=[64, 32], Activation=ReLU, Optimizer=SGD, LR=0.001\n",
            "Test Accuracy: 66.67%\n",
            "Training with Architecture=[64, 32], Activation=ReLU, Optimizer=SGD, LR=0.01\n",
            "Test Accuracy: 80.95%\n",
            "Training with Architecture=[64, 32], Activation=ReLU, Optimizer=RMSprop, LR=0.001\n",
            "Test Accuracy: 83.33%\n",
            "Training with Architecture=[64, 32], Activation=ReLU, Optimizer=RMSprop, LR=0.01\n",
            "Test Accuracy: 80.95%\n",
            "Training with Architecture=[64, 32], Activation=Tanh, Optimizer=Adam, LR=0.001\n",
            "Test Accuracy: 76.19%\n",
            "Training with Architecture=[64, 32], Activation=Tanh, Optimizer=Adam, LR=0.01\n",
            "Test Accuracy: 78.57%\n",
            "Training with Architecture=[64, 32], Activation=Tanh, Optimizer=SGD, LR=0.001\n",
            "Test Accuracy: 73.81%\n",
            "Training with Architecture=[64, 32], Activation=Tanh, Optimizer=SGD, LR=0.01\n",
            "Test Accuracy: 80.95%\n",
            "Training with Architecture=[64, 32], Activation=Tanh, Optimizer=RMSprop, LR=0.001\n",
            "Test Accuracy: 76.19%\n",
            "Training with Architecture=[64, 32], Activation=Tanh, Optimizer=RMSprop, LR=0.01\n",
            "Test Accuracy: 80.95%\n",
            "Training with Architecture=[64, 32], Activation=Sigmoid, Optimizer=Adam, LR=0.001\n",
            "Test Accuracy: 76.19%\n",
            "Training with Architecture=[64, 32], Activation=Sigmoid, Optimizer=Adam, LR=0.01\n",
            "Test Accuracy: 76.19%\n",
            "Training with Architecture=[64, 32], Activation=Sigmoid, Optimizer=SGD, LR=0.001\n",
            "Test Accuracy: 52.38%\n",
            "Training with Architecture=[64, 32], Activation=Sigmoid, Optimizer=SGD, LR=0.01\n",
            "Test Accuracy: 76.19%\n",
            "Training with Architecture=[64, 32], Activation=Sigmoid, Optimizer=RMSprop, LR=0.001\n",
            "Test Accuracy: 76.19%\n",
            "Training with Architecture=[64, 32], Activation=Sigmoid, Optimizer=RMSprop, LR=0.01\n",
            "Test Accuracy: 78.57%\n",
            "Training with Architecture=[128, 64, 32], Activation=ReLU, Optimizer=Adam, LR=0.001\n",
            "Test Accuracy: 80.95%\n",
            "Training with Architecture=[128, 64, 32], Activation=ReLU, Optimizer=Adam, LR=0.01\n",
            "Test Accuracy: 73.81%\n",
            "Training with Architecture=[128, 64, 32], Activation=ReLU, Optimizer=SGD, LR=0.001\n",
            "Test Accuracy: 54.76%\n",
            "Training with Architecture=[128, 64, 32], Activation=ReLU, Optimizer=SGD, LR=0.01\n",
            "Test Accuracy: 78.57%\n",
            "Training with Architecture=[128, 64, 32], Activation=ReLU, Optimizer=RMSprop, LR=0.001\n",
            "Test Accuracy: 80.95%\n",
            "Training with Architecture=[128, 64, 32], Activation=ReLU, Optimizer=RMSprop, LR=0.01\n",
            "Test Accuracy: 83.33%\n",
            "Training with Architecture=[128, 64, 32], Activation=Tanh, Optimizer=Adam, LR=0.001\n",
            "Test Accuracy: 76.19%\n",
            "Training with Architecture=[128, 64, 32], Activation=Tanh, Optimizer=Adam, LR=0.01\n",
            "Test Accuracy: 78.57%\n",
            "Training with Architecture=[128, 64, 32], Activation=Tanh, Optimizer=SGD, LR=0.001\n",
            "Test Accuracy: 69.05%\n",
            "Training with Architecture=[128, 64, 32], Activation=Tanh, Optimizer=SGD, LR=0.01\n",
            "Test Accuracy: 76.19%\n",
            "Training with Architecture=[128, 64, 32], Activation=Tanh, Optimizer=RMSprop, LR=0.001\n",
            "Test Accuracy: 76.19%\n",
            "Training with Architecture=[128, 64, 32], Activation=Tanh, Optimizer=RMSprop, LR=0.01\n",
            "Test Accuracy: 73.81%\n",
            "Training with Architecture=[128, 64, 32], Activation=Sigmoid, Optimizer=Adam, LR=0.001\n",
            "Test Accuracy: 71.43%\n",
            "Training with Architecture=[128, 64, 32], Activation=Sigmoid, Optimizer=Adam, LR=0.01\n",
            "Test Accuracy: 73.81%\n",
            "Training with Architecture=[128, 64, 32], Activation=Sigmoid, Optimizer=SGD, LR=0.001\n",
            "Test Accuracy: 52.38%\n",
            "Training with Architecture=[128, 64, 32], Activation=Sigmoid, Optimizer=SGD, LR=0.01\n",
            "Test Accuracy: 52.38%\n",
            "Training with Architecture=[128, 64, 32], Activation=Sigmoid, Optimizer=RMSprop, LR=0.001\n",
            "Test Accuracy: 71.43%\n",
            "Training with Architecture=[128, 64, 32], Activation=Sigmoid, Optimizer=RMSprop, LR=0.01\n",
            "Test Accuracy: 76.19%\n",
            "Training with Architecture=[256, 128, 64, 32], Activation=ReLU, Optimizer=Adam, LR=0.001\n",
            "Test Accuracy: 80.95%\n",
            "Training with Architecture=[256, 128, 64, 32], Activation=ReLU, Optimizer=Adam, LR=0.01\n",
            "Test Accuracy: 78.57%\n",
            "Training with Architecture=[256, 128, 64, 32], Activation=ReLU, Optimizer=SGD, LR=0.001\n",
            "Test Accuracy: 52.38%\n",
            "Training with Architecture=[256, 128, 64, 32], Activation=ReLU, Optimizer=SGD, LR=0.01\n",
            "Test Accuracy: 78.57%\n",
            "Training with Architecture=[256, 128, 64, 32], Activation=ReLU, Optimizer=RMSprop, LR=0.001\n",
            "Test Accuracy: 80.95%\n",
            "Training with Architecture=[256, 128, 64, 32], Activation=ReLU, Optimizer=RMSprop, LR=0.01\n",
            "Test Accuracy: 76.19%\n",
            "Training with Architecture=[256, 128, 64, 32], Activation=Tanh, Optimizer=Adam, LR=0.001\n",
            "Test Accuracy: 78.57%\n",
            "Training with Architecture=[256, 128, 64, 32], Activation=Tanh, Optimizer=Adam, LR=0.01\n",
            "Test Accuracy: 78.57%\n",
            "Training with Architecture=[256, 128, 64, 32], Activation=Tanh, Optimizer=SGD, LR=0.001\n",
            "Test Accuracy: 73.81%\n",
            "Training with Architecture=[256, 128, 64, 32], Activation=Tanh, Optimizer=SGD, LR=0.01\n",
            "Test Accuracy: 76.19%\n",
            "Training with Architecture=[256, 128, 64, 32], Activation=Tanh, Optimizer=RMSprop, LR=0.001\n",
            "Test Accuracy: 78.57%\n",
            "Training with Architecture=[256, 128, 64, 32], Activation=Tanh, Optimizer=RMSprop, LR=0.01\n",
            "Test Accuracy: 71.43%\n",
            "Training with Architecture=[256, 128, 64, 32], Activation=Sigmoid, Optimizer=Adam, LR=0.001\n",
            "Test Accuracy: 69.05%\n",
            "Training with Architecture=[256, 128, 64, 32], Activation=Sigmoid, Optimizer=Adam, LR=0.01\n",
            "Test Accuracy: 78.57%\n",
            "Training with Architecture=[256, 128, 64, 32], Activation=Sigmoid, Optimizer=SGD, LR=0.001\n",
            "Test Accuracy: 52.38%\n",
            "Training with Architecture=[256, 128, 64, 32], Activation=Sigmoid, Optimizer=SGD, LR=0.01\n",
            "Test Accuracy: 52.38%\n",
            "Training with Architecture=[256, 128, 64, 32], Activation=Sigmoid, Optimizer=RMSprop, LR=0.001\n",
            "Test Accuracy: 73.81%\n",
            "Training with Architecture=[256, 128, 64, 32], Activation=Sigmoid, Optimizer=RMSprop, LR=0.01\n",
            "Test Accuracy: 52.38%\n",
            "Best Model Accuracy: 83.33%\n",
            "Best Model Parameters: [[64, 32], <class 'torch.nn.modules.activation.ReLU'>, 'Adam', 40]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bdc3199a-80a9-4a63-a2d7-56ed2d16755c",
      "metadata": {
        "id": "bdc3199a-80a9-4a63-a2d7-56ed2d16755c"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "df1eaa39-d9bd-410c-beb5-9ca37bdf3d32",
      "metadata": {
        "id": "df1eaa39-d9bd-410c-beb5-9ca37bdf3d32"
      },
      "source": [
        "### Write your report here"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "142f066b-5655-4e1e-9bb1-ae4cc5f54565",
      "metadata": {
        "id": "142f066b-5655-4e1e-9bb1-ae4cc5f54565"
      },
      "source": [
        "1. Step 1: Loading the data\n",
        "* After setting up imports I simply load the data\n",
        "* Since there were no specifics, I used pandas just because I am more comfortable with it\n",
        "* Also helped me confirm that the data wasn't filled with nulls\n",
        "* I skipped all preprocessing and cleaning except labelling and standardizing as per assignment instructions."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Step 2: Splitting the data\n",
        "* Since no cleaning was required, I moved to splitting the data into a standard 80-20 train test split.\n",
        "* Then I performed some basic data conversions using pytorch so I can use the data in neural network training."
      ],
      "metadata": {
        "id": "vdQM1TUqMc2c"
      },
      "id": "vdQM1TUqMc2c"
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Step 3: Building model funciton\n",
        "* Since I need to test mutliple types of networks I decided to make the building training and evaluating portions functions.\n",
        "* The function takes in an input size, architecture, output size and activation function.\n",
        "* Then it constructs a neural network layer for each number of nodes as mentioned per layer and adds the activation function specified to each layer\n",
        "* It returns a model of the defined architectural configuration, with the specified activation function and output size.\n",
        "* Input size is feature length, and output size is 2, since we're predicting between 2 possible outcomes."
      ],
      "metadata": {
        "id": "QXHP9jQCMhHt"
      },
      "id": "QXHP9jQCMhHt"
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Step 4: Training Models\n",
        "* Inputs: Takes in the previously built model, the training data loader to perform batch-wise training, and an optimizer as well as a learning rate.\n",
        "* Epochs: I found that around 40 epochs performed most optimally, after which the perfromance started degrading, while also keeping training time low.\n",
        "* I used CrossEntropyLoss to find the loss in each epoch\n",
        "* This function allows for three optimizers to be used with it, ADAM, SGD, or RSMprop, and this could probably be extended in the future.\n",
        "* Also added tensorboard logging here.\n",
        "* In the loop itself,\n",
        "  * Set the model to training mode.\n",
        "  * Reset temporary variables\n",
        "  * Processes each batch:\n",
        "    * Computes model predictions.\n",
        "    * Calculate the loss\n",
        "    * Backpropagate loss and update model parameters\n",
        "  * Tracks cumulative loss and accuracy metrics.\n",
        "  * Logs the average loss and training accuracy to TensorBoard for each epoch.\n",
        "* This procedure will let me train different models efficiently since all updates and changes are made per model optimizer/architecture/etc.\n"
      ],
      "metadata": {
        "id": "nsiVhTtpMix1"
      },
      "id": "nsiVhTtpMix1"
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Step 5: Evaluating Model\n",
        "\n",
        "* Simple function to test the trained models performance on the test data.\n",
        "* Returns a percentage of accuracy.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "9peS4GivMkSh"
      },
      "id": "9peS4GivMkSh"
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Step 6: Main Loop\n",
        "* Finally, we put these function together for a multitude of combinations to see which model performs best.\n",
        "* Reasoning for architectures - seeing whether layer size and number of layers influences the performance so I increased oth linearly to see if there was positive correlation\n",
        "* Reasoning for activation functions :\n",
        " * ReLu - reduces the risk of vanishing graidents, and can produce quick convergences\n",
        " * Tanh - helps guage any negative values, which might be present, since I didn't examine the entirey of the dataset\n",
        " * Sigmoid - Standard binary classifcation activation function\n",
        "* Reasoning for optimizers - these were easily available optimizers, all of which make sense withing the context of the task.\n",
        " * SGD - Good generalisation because of stable descent\n",
        " * RSMprop - Something I wanted to test as an option.\n",
        " * Adam - generally accepted as a good optimizer and works well for most use cases.\n",
        "* Reasoning for learning rates - similar to architectures I wanted to see whether there was a some magnitude of a power of 10 that was most efficient.\n"
      ],
      "metadata": {
        "id": "-aGxXOahMlcU"
      },
      "id": "-aGxXOahMlcU"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lessons:\n",
        "* Tracking metrics with tensorboard, efficiency of neural networks and necessity to try different optimizers, activation functions and architectures, to find a good combination of variables."
      ],
      "metadata": {
        "id": "VxwWj5NSMpXH"
      },
      "id": "VxwWj5NSMpXH"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Future Applications\n",
        "* I have known about neural networks for a while, so I have used them before. I am currently working on using neural networks for financial applications. It also seems evident to me that a lot of research occurs in this area, especially with understaning what is being learned, to reduce the black box effect. That would be a great area to read into as well."
      ],
      "metadata": {
        "id": "YF_q4hNyMqQs"
      },
      "id": "YF_q4hNyMqQs"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Conclusions\n",
        "* Over multiple iterations I found that the Best Model Accuracy was 88.10%\n",
        "with this configuration:\n",
        "* Best Model Parameters: [[256, 128, 64, 32], <class 'torch.nn.modules.activation.ReLU'>, 'Adam', 40]\n",
        "* This means the the neural network with the above settings can accurately predict whether the sonar signal bounced off of metal or rock 88% of the time."
      ],
      "metadata": {
        "id": "aC20qKJhMrxo"
      },
      "id": "aC20qKJhMrxo"
    },
    {
      "cell_type": "markdown",
      "id": "e353c9e6-e532-42c3-9288-3c50ed48a32f",
      "metadata": {
        "id": "e353c9e6-e532-42c3-9288-3c50ed48a32f"
      },
      "source": [
        "---"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}